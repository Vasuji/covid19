{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Objective\n",
    "\n",
    "Here we want to understand the raw data and try to isolate the data for different purpose (e.g., text mining, indexing, network-data for citation network). This notebook will walk you through collecting all data file-names in a python list and provide you a internal structure of the document. We will go through isolation of text data and citation mapping table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Accessing Data\n",
    "\n",
    "In this section we have collected all data file address which are 'json' type into a python list called datafiles. It will be easy to handle these files later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import json\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "datafiles = []\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        ifile = os.path.join(dirname, filename)\n",
    "        if ifile.split(\".\")[-1] == \"json\":\n",
    "            datafiles.append(ifile)\n",
    "        #print(ifile)\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datafiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some sample data file address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sample Data Exploration\n",
    "\n",
    "Let's see contents of a single sample file one by one. We can use jeson package to read a sample file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(datafiles[0], 'r')as f1:\n",
    "    sample = json.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in sample.items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample['metadata'].keys())\n",
    "print('abstract: ',sample['abstract'][0].keys())\n",
    "print('body_text: ',sample['body_text'][0].keys())\n",
    "print('bib_entries: ',sample['bib_entries'].keys())\n",
    "print('ref_entries: ', sample['ref_entries'].keys())\n",
    "print('back_matter: ',sample['back_matter'][0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1. Collecting all titles**\n",
    "\n",
    "What if you want to analyse all title involved in the dataset? Here is one method to colect all title alongwith doc id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2title = []\n",
    "for file in datafiles:\n",
    "    with open(file,'r')as f:\n",
    "        doc = json.load(f)\n",
    "    id = doc['paper_id'] \n",
    "    title = doc['metadata']['title']\n",
    "    id2title.append({id:title})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2title[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can save this file as json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('id2title.json','w')as f2:\n",
    "#    json.dump(id2title,f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 Collecting All Abstract**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2abstract = []\n",
    "for file in datafiles:\n",
    "    with open(file,'r')as f:\n",
    "        doc = json.load(f)\n",
    "    id = doc['paper_id'] \n",
    "    abstract = ''\n",
    "    for item in doc['abstract']:\n",
    "        abstract = abstract + item['text']\n",
    "        \n",
    "    id2abstract.append({id:abstract})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2abstract[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('id2abstract.json','w')as f3:\n",
    "#   json.dump(id2abstract,f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2bodytext = []\n",
    "for file in datafiles:\n",
    "    with open(file,'r')as f:\n",
    "        doc = json.load(f)\n",
    "    id = doc['paper_id'] \n",
    "    bodytext = ''\n",
    "    for item in doc['body_text']:\n",
    "        bodytext = bodytext + item['text']\n",
    "        \n",
    "    id2bodytext.append({id:bodytext})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#id2bodytext[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('id2bodytext.json','w')as f4:\n",
    "#    json.dump(id2bodytext,f4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Citations and References data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to understand structure of bib-entries from a sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibEntries = []\n",
    "for key,value in sample['bib_entries'].items():\n",
    "    refid = key\n",
    "    title = value['title']\n",
    "    year = value['year']\n",
    "    venue = value['venue']\n",
    "    try:\n",
    "        DOI = value['other_ids']['DOI'][0]\n",
    "    except:\n",
    "        DOI = 'NA'\n",
    "        \n",
    "    bibEntries.append({\"refid\": refid,\\\n",
    "                      \"title\":title,\\\n",
    "                      \"year\": year,\\\n",
    "                      \"venue\":venue,\\\n",
    "                      \"DOI\": DOI})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibEntries[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Creating Network data for sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_node(sample['paper_id'])\n",
    "for item in bibEntries:\n",
    "    G.add_node(item['DOI'], title = item['title'], year = item['year'], venue = item['venue'])\n",
    "    G.add_edge(sample['paper_id'], item['DOI'], value = item['refid'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```plt.figure(figsize = [10,8])\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G,with_labels=True, node_size =1500, node_color = 'lightblue')\n",
    "plt.savefig('ref.png')```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](img/ref.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Playing around References:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in list(G.nodes().data('venue')):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for item in list(G.nodes().data('title')):\n",
    "#    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for item in list(G.nodes().data('year')):\n",
    "#    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**See you soon on the next Notebook!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
